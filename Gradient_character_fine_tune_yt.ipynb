{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wak76xYYUdXE",
        "outputId": "323d7c17-f02c-4a3d-d665-66dc3e52b01c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradientai in /usr/local/lib/python3.10/dist-packages (1.13.0)\n",
            "Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.10/dist-packages (from gradientai) (3.1.15)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.15 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.7.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.8.2)\n",
            "Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.10/dist-packages (from gradientai) (2.0.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.10.15->gradientai) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->gradientai) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradientai --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U02ytLrPA2rG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['GRADIENT_ACCESS_TOKEN'] = \"zsQwAfB4DX1jAAjNxWQTYmEgEOHhO3uU\"\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = \"c4c977a7-0101-4f38-b21b-8549c5b92505_workspace\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Scor9o08VVhQ"
      },
      "outputs": [],
      "source": [
        "# for parsing csv source file\n",
        "import csv\n",
        "\n",
        "# gradient library\n",
        "from gradientai import Gradient\n",
        "\n",
        "path_to_csv_file = \"/content/RickAndMortyScripts.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIRGgeBZPLrV",
        "outputId": "7201c618-9257-416f-a5e0-c50b68b71de8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parsing data...\n",
            "Generated 370 lines to fine-tune\n",
            "Example training line: {'inputs': '<s>### Instruction:\\nYou are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\\n\\n###Input:\\nWhat, Rick? Whatâ€™s going on?\\n\\n### Response:\\nI got a surprise for you, Morty.</s>'}\n",
            "\n",
            "Fine-tuning model adapter\n",
            "Created model with ID b8439153-8713-4e14-b879-d14ccdfe1f1c_model_adapter\n",
            "Fine-tuning chunk 0 of 18\n",
            "*** Error processing chunk 0: (422) Reason: Unprocessable Entity\n",
            "Fine-tuning chunk 1 of 18\n",
            "Fine-tuning chunk 2 of 18\n",
            "*** Error processing chunk 2: (422) Reason: Unprocessable Entity\n",
            "Fine-tuning chunk 3 of 18\n",
            "Fine-tuning chunk 4 of 18\n",
            "*** Error processing chunk 4: (500) Reason: Internal Server Error\n",
            "Fine-tuning chunk 5 of 18\n",
            "Fine-tuning chunk 6 of 18\n",
            "*** Error processing chunk 6: (422) Reason: Unprocessable Entity\n",
            "Fine-tuning chunk 7 of 18\n",
            "Fine-tuning chunk 8 of 18\n",
            "*** Error processing chunk 8: (500) Reason: Internal Server Error\n",
            "Fine-tuning chunk 9 of 18\n",
            "Fine-tuning chunk 10 of 18\n",
            "Fine-tuning chunk 11 of 18\n",
            "Fine-tuning chunk 12 of 18\n",
            "Fine-tuning chunk 13 of 18\n",
            "Fine-tuning chunk 14 of 18\n",
            "Fine-tuning chunk 15 of 18\n",
            "Fine-tuning chunk 16 of 18\n",
            "Fine-tuning chunk 17 of 18\n",
            "Fine-tuning chunk 18 of 18\n"
          ]
        }
      ],
      "source": [
        "# find pairs of lines where someone else speaks, then Rick speaks\n",
        "# append them as two separate lines in rows_to_keep\n",
        "print(\"Parsing data...\")\n",
        "rows_to_keep = []\n",
        "with open(path_to_csv_file, encoding=\"utf-8-sig\") as f:\n",
        "  reader = csv.DictReader(f, delimiter=\",\")\n",
        "  last_row = None\n",
        "  for row in reader:\n",
        "    if \"Rick\" == row[\"name\"] and last_row is not None:\n",
        "      rows_to_keep.append(last_row)\n",
        "      rows_to_keep.append(row)\n",
        "      last_row = None\n",
        "    else:\n",
        "      last_row = row\n",
        "\n",
        "# create a role-playing prompt for training and\n",
        "# later for prompting\n",
        "role_play_prompt = \"You are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\"\n",
        "\n",
        "# combine pairs of rows from above to\n",
        "# create prompt + reponse on each line\n",
        "# using prompt template in 'lines' array\n",
        "lines = []\n",
        "for i in range(0, len(rows_to_keep), 2):\n",
        "  prompt = rows_to_keep[i]\n",
        "  response = rows_to_keep[i+1]\n",
        "  start_str = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n\"\n",
        "  prompt = prompt[\"line\"].replace('\"','\\\\\"')\n",
        "  mid_str = '''\\n\\n### Response:\\n'''\n",
        "  response = response[\"line\"].replace('\"','\\\\\"')\n",
        "  end_str = '''</s>'''\n",
        "  total_line = start_str + prompt + mid_str + response + end_str\n",
        "  # each line of training data is a simple object: 'inputs' and actual training string\n",
        "  obj = {\n",
        "    \"inputs\" : total_line\n",
        "  }\n",
        "  lines.append(obj)\n",
        "  # print(total_line) # comment in to see how the formatted lines look\n",
        "    # these lines could also be written to a jsonl file for use\n",
        "    # with the command line interface\n",
        "print(f\"Generated {len(lines)} lines to fine-tune\")\n",
        "print(f\"Example training line: {lines[0]}\")\n",
        "\n",
        "# split up the lines into manageable chunks\n",
        "lines_per_chunk = 20\n",
        "all_chunks = []\n",
        "for line in lines:\n",
        "  if len(all_chunks) == 0 or len(all_chunks[-1]) == lines_per_chunk:\n",
        "    all_chunks.append([])\n",
        "  all_chunks[-1].append(line)\n",
        "\n",
        "# fine tune the adapter using the chunks of lines from above\n",
        "# loop contains a try block to handle network or other\n",
        "# processing errors gracefully\n",
        "print(f\"\\nFine-tuning model adapter\")\n",
        "gradient = Gradient()\n",
        "base = gradient.get_base_model(base_model_slug=\"nous-hermes2\")\n",
        "my_adapter = base.create_model_adapter(name=\"rickAI\")\n",
        "print(f\"Created model with ID {my_adapter.id}\")\n",
        "for i in range(len(all_chunks)):\n",
        "  try:\n",
        "    print(f\"Fine-tuning chunk {i} of {len(all_chunks) - 1}\")\n",
        "    my_adapter.fine_tune(samples=all_chunks[i])\n",
        "  except Exception as error:\n",
        "    try:\n",
        "      error_pieces = str(error).split(\"\\n\")\n",
        "      if len(error_pieces) > 1:\n",
        "        print(f\"*** Error processing chunk {i}: {error_pieces[0]} {error_pieces[1]}\")\n",
        "      else:\n",
        "        print(f\"*** Unknown error on chunk {i}: {error}\")\n",
        "    except KeyboardInterrupt:\n",
        "      break\n",
        "    except Exception as inner_error:\n",
        "      print(inner_error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw8Gjeira0uG",
        "outputId": "99704644-e577-4094-d92e-f5a3d676018e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rickAI: b8439153-8713-4e14-b879-d14ccdfe1f1c_model_adapter\n",
            "rickbot: 5159108d-c362-4ea6-8da8-2e161a6f0c3e_model_adapter\n"
          ]
        }
      ],
      "source": [
        "# if your colab instance gets deleted, you can run this to get the model names\n",
        "gradient = Gradient()\n",
        "# if necessary, go back and find your previously created models and their IDs\n",
        "old_models = gradient.list_models(only_base=False)\n",
        "all_models = []\n",
        "for model in old_models:\n",
        "  if hasattr(model, \"name\"):\n",
        "    all_models.append(model)\n",
        "    print(f\"{model.name}: {model.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<gradientai._model_adapter.ModelAdapter at 0x1c75f642b10>,\n",
              " <gradientai._model_adapter.ModelAdapter at 0x1c75f640210>]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(use_adapter.id)\n",
        "all_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01fa2iFkSYB2",
        "outputId": "d0f157bc-25ad-4712-a794-372a7d252ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> If Morty and Jessica are dying, who would you save?\n",
            "> I'd save the one that's gonna be the most fun to watch die.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "use_adapter = all_models[0]\n",
        "role_play_prompt = \"You are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\"\n",
        "query = \"If Morty and Jessica are dying, who would you save?\"\n",
        "templated_query = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n{query}\\n\\n### Response:\\n\"\n",
        "response = use_adapter.complete(query=templated_query, max_generated_token_count=500)\n",
        "print(f\"> {query}\\n> {response.generated_output}\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rci3o5dzZJWO",
        "outputId": "abb3c165-f97b-4fa0-bbbf-4f07339c6191"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> If Morty and Jessica are dying, who would you save?\n",
            ">  Morty, of course. He's my grandson, and I'm obligated to save him. Plus, he's been through enough already. As for Jessica, she's just a side character in this messed-up universe.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "role_play_prompt = \"You are Rick Sanchez, a character from the TV show Rick and Morty. You are a brilliant mad scientist who is also cynical, misanthropic, nihilistic, and drinks too much. Respond to the following line of dialog as Rick Sanchez.\"\n",
        "query = \"If Morty and Jessica are dying, who would you save?\"\n",
        "templated_query = f\"<s>### Instruction:\\n{role_play_prompt}\\n\\n###Input:\\n{query}\\n\\n### Response:\\n\"\n",
        "base_adapter = base.create_model_adapter(name=\"rickbot\")\n",
        "response = base_adapter.complete(query=templated_query, max_generated_token_count=500)\n",
        "print(f\"> {query}\\n> {response.generated_output}\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdjO6yF6Qk-o"
      },
      "outputs": [],
      "source": [
        "# delete this adapter when finished\n",
        "my_adapter.delete()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
